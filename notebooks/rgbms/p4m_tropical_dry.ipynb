{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ea0f4fa-e4d1-4fb7-af0d-f0660dfa5296",
   "metadata": {},
   "source": [
    "# Image registration for Phantom 4 Multi\n",
    "\n",
    "As it is a Phantom 4M flight without calibration panel, only the images are co-registered, adjusted using the sun-sensor and saved as 4 channel .tifs\n",
    "* For the following Dataset: https://www.sciencedirect.com/science/article/pii/S2352340923009307\n",
    "* Using code snippets from:\n",
    "\n",
    "Output: `uint16` 0-65535 scaled .tif files with green, red, rededge, nir bands\n",
    "\n",
    "\n",
    "1. Extract metadata from TIFF images using tifffile and exifread.\n",
    "2. Normalize raw pixel values using the black level.\n",
    "3. Apply vignetting correction based on the polynomial coefficients from the metadata.\n",
    "4. Apply distortion correction using OpenCV's undistort() function.\n",
    "5. Calculate camera signal values using gain and exposure time.\n",
    "6. Account for irradiance values from the sunlight sensor.\n",
    "7. Compute reflectance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "368f6d30-9a4a-4d43-8a67-e10b096ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "from PIL import Image\n",
    "import piexif\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "import tifftools\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "from tifffile import TiffFile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "class XmlListConfig(list):\n",
    "    def __init__(self, aList):\n",
    "        for element in aList:\n",
    "            if element:\n",
    "                # treat like dict\n",
    "                if len(element) == 1 or element[0].tag != element[1].tag:\n",
    "                    self.append(XmlDictConfig(element))\n",
    "                # treat like list\n",
    "                elif element[0].tag == element[1].tag:\n",
    "                    self.append(XmlListConfig(element))\n",
    "            elif element.text:\n",
    "                text = element.text.strip()\n",
    "                if text:\n",
    "                    self.append(text)\n",
    "\n",
    "\n",
    "class XmlDictConfig(dict):\n",
    "    '''\n",
    "    Example usage:\n",
    "\n",
    "    >>> tree = ElementTree.parse('your_file.xml')\n",
    "    >>> root = tree.getroot()\n",
    "    >>> xmldict = XmlDictConfig(root)\n",
    "\n",
    "    Or, if you want to use an XML string:\n",
    "\n",
    "    >>> root = ElementTree.XML(xml_string)\n",
    "    >>> xmldict = XmlDictConfig(root)\n",
    "\n",
    "    And then use xmldict for what it is... a dict.\n",
    "    '''\n",
    "    def __init__(self, parent_element):\n",
    "        if parent_element.items():\n",
    "            self.update(dict(parent_element.items()))\n",
    "        for element in parent_element:\n",
    "            if element:\n",
    "                # treat like dict - we assume that if the first two tags\n",
    "                # in a series are different, then they are all different.\n",
    "                if len(element) == 1 or element[0].tag != element[1].tag:\n",
    "                    aDict = XmlDictConfig(element)\n",
    "                # treat like list - we assume that if the first two tags\n",
    "                # in a series are the same, then the rest are the same.\n",
    "                else:\n",
    "                    # here, we put the list in dictionary; the key is the\n",
    "                    # tag name the list elements all share in common, and\n",
    "                    # the value is the list itself \n",
    "                    aDict = {element[0].tag: XmlListConfig(element)}\n",
    "                # if the tag has attributes, add those to the dict\n",
    "                if element.items():\n",
    "                    aDict.update(dict(element.items()))\n",
    "                self.update({element.tag: aDict})\n",
    "            # this assumes that if you've got an attribute in a tag,\n",
    "            # you won't be having any text. This may or may not be a \n",
    "            # good idea -- time will tell. It works for the way we are\n",
    "            # currently doing XML configuration files...\n",
    "            elif element.items():\n",
    "                self.update({element.tag: dict(element.items())})\n",
    "            # finally, if there are no child tags and no attributes, extract\n",
    "            # the text\n",
    "            else:\n",
    "                self.update({element.tag: element.text})\n",
    "\n",
    "\n",
    "def calibrate_image(nir_image, metadata):\n",
    "    # Parse the metadata\n",
    "    root = ET.fromstring(metadata[\"XMP\"])\n",
    "    xmldict = XmlDictConfig(root)\n",
    "    base = xmldict['{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF']['{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description']\n",
    "    gimbal_r = base['{http://www.dji.com/drone-dji/1.0/}GimbalReverse']\n",
    "    \n",
    "    # Extract necessary metadata values\n",
    "    black_level = 4096  # Fixed value\n",
    "    vignetting_coeffs = [float(k) for k in base['{http://www.dji.com/drone-dji/1.0/}VignettingData'].split(\",\")]  # Extract vignetting coefficients\n",
    "    center_x = float(base['{http://www.dji.com/drone-dji/1.0/}CalibratedOpticalCenterX'])\n",
    "    center_y = float(base['{http://www.dji.com/drone-dji/1.0/}CalibratedOpticalCenterY'])\n",
    "    sensor_gain = float(base['{http://www.dji.com/drone-dji/1.0/}SensorGain'])\n",
    "    exposure_time = float(base['{http://www.dji.com/drone-dji/1.0/}ExposureTime'])\n",
    "    irradiance = float(base['{http://www.dji.com/drone-dji/1.0/}Irradiance'])  # NIR_LS * p_LSNIR\n",
    "    \n",
    "    # Step 1: Normalize the raw pixel values\n",
    "    nir_camera = (nir_image / 65535 - black_level / 65535) * 1e6 / (sensor_gain * exposure_time)\n",
    "    \n",
    "    # Step 2: Apply vignetting correction\n",
    "    height, width = nir_image.shape\n",
    "    x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    r = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
    "    vignetting_correction = sum([vignetting_coeffs[i] * r ** i for i in range(len(vignetting_coeffs))]) + 1.0\n",
    "    nir_camera_corrected = nir_camera * vignetting_correction\n",
    "\n",
    "\n",
    "    dewarp = base['{http://www.dji.com/drone-dji/1.0/}DewarpData'].split(\",\")\n",
    "    # Step 3: Apply distortion correction\n",
    "    fx = float(dewarp[0].split(\";\")[1])\n",
    "    fy = float(dewarp[1])\n",
    "    cx = float(dewarp[2])\n",
    "    cy = float(dewarp[3])\n",
    "    \n",
    "    camera_matrix = np.array([[fx, 0, center_x + cx],\n",
    "                              [0, fy, center_y + cy],\n",
    "                              [0, 0, 1]])\n",
    "    \n",
    "    k1 = float(dewarp[-5])\n",
    "    k2 = float(dewarp[-4])\n",
    "    p1 = float(dewarp[-3])\n",
    "    p2 = float(dewarp[-2])\n",
    "    k3 = float(dewarp[-1])\n",
    "\n",
    "    dist_coeffs = np.array([k1,k2,p1,p2,k3])\n",
    "    \n",
    "    # Apply distortion correction\n",
    "    nir_camera_undistorted = cv2.undistort(nir_camera_corrected, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Step 4: Calculate reflectance\n",
    "    reflectance = nir_camera_undistorted / irradiance\n",
    "    \n",
    "    # Save the reflectance image\n",
    "    return reflectance\n",
    "\n",
    "    \n",
    "# Utility functions\n",
    "def load_image(filename):\n",
    "    \"\"\"Load a single image with the metadata as byte dump.\"\"\"\n",
    "    image = np.asarray(Image.open(filename))\n",
    "\n",
    "    t = TiffFile(filename)\n",
    "    metadata = t.pages[0].tags\n",
    "    \n",
    "    # Convert tifftags to a dictionary\n",
    "    metadata_dict = {tag.name: tag.value for tag in metadata.values()}\n",
    "    metadata_dict[\"XMP\"] = metadata_dict[\"XMP\"].decode(\"utf-8\")\n",
    "    #metadata_dict[\"ExifTag\"][\"FileSource\"] = metadata_dict[\"ExifTag\"][\"FileSource\"].decode()\n",
    "    #metadata_dict[\"ExifTag\"][\"SceneType\"] = metadata_dict[\"ExifTag\"][\"SceneType\"].decode()\n",
    "    metadata_dict[\"GPSTag\"][\"GPSVersionID\"] = tuple(metadata_dict[\"GPSTag\"][\"GPSVersionID\"])\n",
    "    #metadata_dict[\"XPComment\"] = list(metadata_dict[\"XPComment\"])\n",
    "    #metadata_dict['XPKeywords'] = metadata_dict['XPKeywords'].decode()\n",
    "    metadata_dict[\"ExifTag\"][\"MakerNote\"] = 0\n",
    "    return image, metadata_dict\n",
    "    \n",
    "import xml.etree.ElementTree as ET\n",
    "def process_xml_dict_3m(xml_string):\n",
    "    \n",
    "    root = ET.fromstring(xml_string)\n",
    "    xmldict = XmlDictConfig(root)\n",
    "    return xmldict\n",
    "    \n",
    "def save_image(filename, image, metadata=None):\n",
    "    \"\"\"Save the image as a 4-channel TIFF using tifffile.\"\"\"\n",
    "    tifffile.imwrite(filename, image, photometric='rgb',metadata=metadata)\n",
    "\n",
    "# Create a directory to save homographies\n",
    "os.makedirs(\"homographies\", exist_ok=True)\n",
    "\n",
    "\n",
    "def align_images(image1, image2, band_name, base_name, set_title = \"set\"):\n",
    "    \"\"\"Align two images using ORB keypoints and cached affine transformation with quantization.\"\"\"\n",
    "    # Create a unique transformation filename\n",
    "\n",
    "    affine_filename = f\"homographies/{band_name}_{set_title}_affine.npy\"\n",
    "\n",
    "    # Quantize images to uint8 if necessary\n",
    "    image1_8bit = quantize_to_uint8(image1)\n",
    "    image2_8bit = quantize_to_uint8(image2)\n",
    "\n",
    "    # Check if the affine transformation is already cached\n",
    "    if os.path.exists(affine_filename):\n",
    "        affine_matrix = np.load(affine_filename)\n",
    "    else:\n",
    "        # Convert images to grayscale if they are RGB\n",
    "        if len(image1_8bit.shape) == 3 and image1_8bit.shape[-1] == 3:\n",
    "            gray1 = cv2.cvtColor(image1_8bit, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray1 = image1_8bit\n",
    "\n",
    "        if len(image2_8bit.shape) == 3 and image2_8bit.shape[-1] == 3:\n",
    "            gray2 = cv2.cvtColor(image2_8bit, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray2 = image2_8bit\n",
    "\n",
    "        # Use ORB to find keypoints and descriptors\n",
    "        orb = cv2.ORB_create(50000)\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "        # Match descriptors using FLANN-based matcher\n",
    "        index_params = dict(algorithm=6, table_number=12, key_size=20, multi_probe_level=2)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "        # Filter matches using the ratio test\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.8 * n.distance]\n",
    "\n",
    "        if len(good_matches) < 3:\n",
    "            raise ValueError(\"Not enough good matches to compute affine transformation.\")\n",
    "\n",
    "        # Extract matched points\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Compute the affine transformation\n",
    "        affine_matrix, _ = cv2.estimateAffinePartial2D(dst_pts, src_pts, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "        # Save the affine transformation to disk\n",
    "        np.save(affine_filename, affine_matrix)\n",
    "\n",
    "    # Apply the affine transformation\n",
    "    sz = image1.shape\n",
    "    aligned_image = cv2.warpAffine(image2, affine_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return aligned_image\n",
    "\n",
    "def quantize_to_uint8(image):\n",
    "    \"\"\"Convert an image to uint8, scaling values if necessary.\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        if image.max() > 255:\n",
    "            image = (image / image.max()) * 255\n",
    "        image = image.astype(np.uint8)\n",
    "    return image\n",
    "def create_4_channel_image(green_image, red_image, rededge_image, nir_image):\n",
    "    \"\"\"Create a 4-channel image (G, R, RE, NIR).\"\"\"\n",
    "    return np.stack((green_image, red_image, rededge_image, nir_image), axis=-1)\n",
    "    \n",
    "def rescale_to_uint16(da):\n",
    "    da = np.where(np.isnan(da), 65535, da)\n",
    "    rescaled = (da * 65535).clip(0, 65535).astype(np.uint16)\n",
    "    \n",
    "    return rescaled\n",
    "    \n",
    "\n",
    "def process_multispec_set(green_path, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \"\"\"Process one set of multispectral images and save as a 4-channel TIFF.\"\"\"\n",
    "    \n",
    "    green_image, g_metadata = load_image(green_path)\n",
    "\n",
    "    dirname = os.path.dirname(green_path)\n",
    "\n",
    "    g_id = int(green_path[-8:-4])\n",
    "    rgb_id = (\"RGB\", f\"{g_id - 2:04d}\")\n",
    "    b_id = (\"B\", f\"{g_id - 1:04d}\")\n",
    "    r_id = (\"R\", f\"{g_id + 1:04d}\")\n",
    "    re_id= (\"RE\", f\"{g_id + 2:04d}\")\n",
    "    nir_id= (\"NIR\", f\"{g_id + 3:04d}\")\n",
    "\n",
    "    bands = {}\n",
    "    for nom, number in [b_id, r_id, re_id, nir_id]:\n",
    "        file= f\"DJI_{number}.tif\"\n",
    "        p = os.path.join(dirname, file)\n",
    "        im, meta = load_image(p)\n",
    "        bands[nom] = im\n",
    "        bands[nom+\"_meta\"] = meta\n",
    "        \n",
    "    \n",
    "    sensor = \"P4M\"\n",
    "    cal = \"SUNCAL\"\n",
    "    set_title = os.path.basename(os.path.normpath(output_directory))\n",
    "    base_name = os.path.basename(green_path).replace(\".tif\", \"\")\n",
    "    output_filename = f\"{sensor}_{cal}_{set_title}_{base_name}.tif\"\n",
    "    rgb_filename = f\"RGB_{set_title}_{base_name}.tif\"\n",
    "    output_path = os.path.join(output_directory, output_filename)\n",
    "    rgb_path = os.path.join(output_directory, rgb_filename)\n",
    "\n",
    "    \n",
    "    # Align each band to the green image using cached homographies\n",
    "    aligned_blue = align_images(green_image, bands[\"B\"], \"B\", base_name, set_title)\n",
    "    \n",
    "    aligned_red = align_images(green_image, bands[\"R\"], \"R\", base_name, set_title)\n",
    "    aligned_rededge = align_images(green_image, bands[\"RE\"], \"RE\", base_name, set_title)\n",
    "    aligned_nir = align_images(green_image, bands[\"NIR\"], \"NIR\", base_name, set_title)\n",
    "\n",
    "    # ALIGN RGB TODO\n",
    "    #load rgb from paralel folder\n",
    "    \n",
    "    file= f\"DJI_{rgb_id[1]}.JPG\"\n",
    "    rgb_path = dirname.replace(\"Multi\", \"RGB\")\n",
    "    rgb_path = os.path.join(rgb_path, file)\n",
    "    if os.path.exists(rgb_path):\n",
    "            \n",
    "        with Image.open(rgb_path) as img:\n",
    "            rgb = np.array(img)\n",
    "    else:\n",
    "        print(f\"Skipping due to missing jpg path: {rgb_path}\")\n",
    "        return\n",
    "        \n",
    "    #reszie to fit? (p4m is both at 1600x1300\n",
    "    aligned_rgb = align_images(green_image, rgb, \"RGB\", base_name, set_title)\n",
    "    \n",
    "    #calibrate reflectance\n",
    "    r_blue = calibrate_image(aligned_blue, bands[\"B_meta\"])\n",
    "    r_green = calibrate_image(green_image, g_metadata) \n",
    "    r_red = calibrate_image(aligned_red, bands[\"R_meta\"]) \n",
    "    r_rededge = calibrate_image(aligned_rededge, bands[\"RE_meta\"]) \n",
    "    r_nir = calibrate_image(aligned_nir, bands[\"NIR_meta\"]) \n",
    "\n",
    "    #rescale to 65535:\n",
    "    b  = rescale_to_uint16(r_blue)\n",
    "    g  = rescale_to_uint16(r_green)\n",
    "    r = rescale_to_uint16(r_red)\n",
    "    re = rescale_to_uint16(r_rededge)\n",
    "    nir = rescale_to_uint16(r_nir)\n",
    "\n",
    "    # Create a 4-channel image\n",
    "    image_4ch = np.stack((b,g,r,re,nir), axis=-1)\n",
    "\n",
    "    # Save the 4-channel image\n",
    "    save_image(output_path, image_4ch,g_metadata)\n",
    "\n",
    "    #save the RGB image\n",
    "    save_image(rgb_path, aligned_rgb, g_metadata)\n",
    "    \n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_directory(input_dir, output_directory):\n",
    "    \"\"\"Process an entire directory with multiple sets of multispectral images.\"\"\"\n",
    "    input_dir = os.path.abspath(input_dir)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    l = os.listdir(input_dir)\n",
    "    # order is 1,2,3,4,5 B, G, R, RED, NIR\n",
    "    # we want to start with Green, and count upwards:\n",
    "    green_images = l[1::5]  # Starts from the 3rd file\n",
    "    green_images = [os.path.join(input_dir, images) for images in green_images]\n",
    "    \n",
    "\n",
    "    # Process sets of 4 multispectral images in parallel with a progress bar\n",
    "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "        list(tqdm(executor.map(process_multispec_set,  green_images, repeat(output_directory)), total=len(green_images)))\n",
    "\n",
    "    print(\"All images successfully processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a1336a4-db73-44cb-84ad-1281abbe04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of threads for parallel processing\n",
    "n_threads = 1\n",
    "# Define termination criteria for the image registration algorithm; empirically determined:\n",
    "number_of_iterations = 100\n",
    "termination_eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7687d0-a133-46e1-ad9f-da7fc627ea18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_29100\\3725193435.py:56: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_29100\\3725193435.py:24: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [09:36<00:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images successfully processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"../../data/RGBMS_pretraining/P4M_tropical_dry/Dry Season/Dry Season Multi\"\n",
    "output_folder = \"../../data/msrgb_processed/p4m_tropical_dry\"\n",
    "\n",
    "process_directory(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c389cc-74c8-4d30-974a-53b392e3089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_29100\\3725193435.py:56: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_29100\\3725193435.py:24: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [06:10<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images successfully processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"../../data/RGBMS_pretraining/P4M_tropical_dry/First Rain Season/Rain Season Multi\"\n",
    "output_folder = \"../../data/msrgb_processed/p4m_tropical_rain\"\n",
    "\n",
    "process_directory(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de43fcaf-bdfe-450a-b13e-c02903b1d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image_bands(folder_path):\n",
    "    \"\"\"Load the first 4-channel TIFF image from the folder and display its bands.\"\"\"\n",
    "    # Find the first TIFF file in the folder\n",
    "    tiff_files = [f for f in os.listdir(folder_path) if f.endswith(\".tif\")]\n",
    "    if not tiff_files:\n",
    "        print(\"No TIFF files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    first_image_path = os.path.join(folder_path, tiff_files[-1])\n",
    "    \n",
    "    # Load the image\n",
    "    image = tiff.imread(first_image_path)\n",
    "    \n",
    "    # Validate that it's a 4-channel image\n",
    "    if image.shape[-1] != 4:\n",
    "        print(\"The image does not have 4 channels.\")\n",
    "        return\n",
    "    \n",
    "    # Extract the bands\n",
    "    green_band = image[:, :, 0]\n",
    "    red_band = image[:, :, 1]\n",
    "    rededge_band = image[:, :, 2]\n",
    "    nir_band = image[:, :, 3]\n",
    "    \n",
    "    # Create a false-color image (NIR, Red, Green)\n",
    "    false_color_image = np.dstack((nir_band, red_band, green_band))\n",
    "    false_color_image = false_color_image / 65535\n",
    "\n",
    "    # Create a 10x zoom of the center crop\n",
    "    height, width, _ = false_color_image.shape\n",
    "    crop_size = (height // 20, width // 20)  # Crop size for a 10x zoom\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "\n",
    "    # Get the cropped region\n",
    "    cropped_image = false_color_image[\n",
    "        center_y - crop_size[0] // 2 : center_y + crop_size[0] // 2,\n",
    "        center_x - crop_size[1] // 2 : center_x + crop_size[1] // 2\n",
    "    ]\n",
    "\n",
    "    # Resize the cropped image to match the original dimensions\n",
    "    zoomed_image = cv2.resize(cropped_image, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # False color image\n",
    "    ax[0, 0].imshow(false_color_image)\n",
    "    ax[0, 0].set_title(\"False Color (NIR, Red, Green)\")\n",
    "    ax[0, 0].axis(\"off\")\n",
    "\n",
    "    # Individual bands\n",
    "    ax[0, 1].imshow(green_band, cmap=\"gray\")\n",
    "    ax[0, 1].set_title(\"Green Band\")\n",
    "    ax[0, 1].axis(\"off\")\n",
    "\n",
    "    ax[0, 2].imshow(red_band, cmap=\"gray\")\n",
    "    ax[0, 2].set_title(\"Red Band\")\n",
    "    ax[0, 2].axis(\"off\")\n",
    "\n",
    "    ax[1, 0].imshow(rededge_band, cmap=\"gray\")\n",
    "    ax[1, 0].set_title(\"RedEdge Band\")\n",
    "    ax[1, 0].axis(\"off\")\n",
    "\n",
    "    ax[1, 1].imshow(nir_band, cmap=\"gray\")\n",
    "    ax[1, 1].set_title(\"NIR Band\")\n",
    "    ax[1, 1].axis(\"off\")\n",
    "\n",
    "    # Zoomed-in section\n",
    "    ax[1, 2].imshow(zoomed_image)\n",
    "    ax[1, 2].set_title(\"20x Zoom (Center Crop)\")\n",
    "    ax[1, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6998e5e-0d2b-4897-bd5f-3167b917bf92",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../data/processed/p4m_tropical_rain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/p4m_tropical_rain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdisplay_image_bands\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mdisplay_image_bands\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the first 4-channel TIFF image from the folder and display its bands.\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Find the first TIFF file in the folder\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m tiff_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tiff_files:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo TIFF files found in the folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../data/processed/p4m_tropical_rain'"
     ]
    }
   ],
   "source": [
    "output_folder = \"../data/processed/p4m_tropical_rain\"\n",
    "display_image_bands(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b775954-6a94-4424-b2a7-2bd0b40d35b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
