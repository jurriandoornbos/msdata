{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90849c0d-523d-4215-8959-3e684d2d6ce8",
   "metadata": {},
   "source": [
    "# Image registration for Mavic 3M\n",
    "As it is a Mavic 3M flight without calibration panel, only the images are co-registered and saved as 4 channel .tifs\n",
    "* For the following Dataset: https://www.sciencedirect.com/science/article/pii/S2352340924004487\n",
    "* Using code snippets from: https://gitlab.com/Yario/image_registration_dji_mavic_3m/-/blob/main/coregistration_mavic_3m_images.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368f6d30-9a4a-4d43-8a67-e10b096ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "from PIL import Image\n",
    "import piexif\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "import tifftools\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "from tifffile import TiffFile\n",
    "import xml.etree.ElementTree as ET\n",
    "# Utility functions\n",
    "\n",
    "def calibrate_image(nir_image, metadata):\n",
    "    # Parse the metadata\n",
    "    root = ET.fromstring(metadata[\"XMP\"])\n",
    "    xmldict = XmlDictConfig(root)\n",
    "    base = xmldict['{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF']['{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description']\n",
    "    gimbal_r = base['{http://www.dji.com/drone-dji/1.0/}GimbalReverse']\n",
    "    \n",
    "    # Extract necessary metadata values\n",
    "    black_level = 4096  # Fixed value\n",
    "    vignetting_coeffs = [float(k) for k in base['{http://www.dji.com/drone-dji/1.0/}VignettingData'].split(\",\")]  # Extract vignetting coefficients\n",
    "    center_x = float(base['{http://www.dji.com/drone-dji/1.0/}CalibratedOpticalCenterX'])\n",
    "    center_y = float(base['{http://www.dji.com/drone-dji/1.0/}CalibratedOpticalCenterY'])\n",
    "    sensor_gain = float(base['{http://www.dji.com/drone-dji/1.0/}SensorGain'])\n",
    "    exposure_time = float(base['{http://www.dji.com/drone-dji/1.0/}ExposureTime'])\n",
    "    irradiance = float(base['{http://www.dji.com/drone-dji/1.0/}Irradiance'])  # NIR_LS * p_LSNIR\n",
    "    \n",
    "    # Step 1: Normalize the raw pixel values\n",
    "    nir_camera = (nir_image / 65535 - black_level / 65535) * 1e6 / (sensor_gain * exposure_time)\n",
    "    \n",
    "    # Step 2: Apply vignetting correction\n",
    "    height, width = nir_image.shape\n",
    "    x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    r = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
    "    vignetting_correction = sum([vignetting_coeffs[i] * r ** i for i in range(len(vignetting_coeffs))]) + 1.0\n",
    "    nir_camera_corrected = nir_camera * vignetting_correction\n",
    "\n",
    "\n",
    "    dewarp = base['{http://www.dji.com/drone-dji/1.0/}DewarpData'].split(\",\")\n",
    "    # Step 3: Apply distortion correction\n",
    "    fx = float(dewarp[0].split(\";\")[1])\n",
    "    fy = float(dewarp[1])\n",
    "    cx = float(dewarp[2])\n",
    "    cy = float(dewarp[3])\n",
    "    \n",
    "    camera_matrix = np.array([[fx, 0, center_x + cx],\n",
    "                              [0, fy, center_y + cy],\n",
    "                              [0, 0, 1]])\n",
    "    \n",
    "    k1 = float(dewarp[-5])\n",
    "    k2 = float(dewarp[-4])\n",
    "    p1 = float(dewarp[-3])\n",
    "    p2 = float(dewarp[-2])\n",
    "    k3 = float(dewarp[-1])\n",
    "\n",
    "    dist_coeffs = np.array([k1,k2,p1,p2,k3])\n",
    "    \n",
    "    # Apply distortion correction\n",
    "    nir_camera_undistorted = cv2.undistort(nir_camera_corrected, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Step 4: Calculate reflectance\n",
    "    reflectance = nir_camera_undistorted / irradiance\n",
    "    \n",
    "    # Save the reflectance image\n",
    "    return reflectance\n",
    "\n",
    "\n",
    "def load_image(filename):\n",
    "    \"\"\"Load a single image with the metadata as byte dump.\"\"\"\n",
    "    image = np.asarray(Image.open(filename))\n",
    "\n",
    "    t = TiffFile(filename)\n",
    "    metadata = t.pages[0].tags\n",
    "    \n",
    "\n",
    "    \n",
    "    # Convert tifftags to a dictionary\n",
    "    metadata_dict = {tag.name: tag.value for tag in metadata.values()}\n",
    "    metadata_dict[\"XMP\"] = metadata_dict[\"XMP\"].decode(\"utf-8\")\n",
    "    metadata_dict[\"ExifTag\"][\"FileSource\"] = metadata_dict[\"ExifTag\"][\"FileSource\"].decode()\n",
    "    metadata_dict[\"ExifTag\"][\"SceneType\"] = metadata_dict[\"ExifTag\"][\"SceneType\"].decode()\n",
    "    metadata_dict[\"GPSTag\"][\"GPSVersionID\"] = tuple(metadata_dict[\"GPSTag\"][\"GPSVersionID\"])\n",
    "    metadata_dict[\"XPComment\"] = list(metadata_dict[\"XPComment\"])\n",
    "    metadata_dict['XPKeywords'] = metadata_dict['XPKeywords'].decode()\n",
    "\n",
    "    tags = metadata\n",
    "    exif_ifd = tags.get(34665)  # Exif IFD tag\n",
    "    gps_ifd = tags.get(34853)   # GPS IFD tag\n",
    "    \n",
    "    # Step 2: Convert tags to extratags format\n",
    "    extratags = []\n",
    "    subifds = []\n",
    "        # Handle Exif IFD\n",
    "    if exif_ifd:\n",
    "        subifds.append(exif_ifd.value)\n",
    "        #extratags.append((34665, 'I', 1, 0))  # Pointer to the first sub-IFD\n",
    "    \n",
    "    # Handle GPS IFD\n",
    "    if gps_ifd:\n",
    "        subifds.append(gps_ifd.value)\n",
    "        #extratags.append((34853, 'I', 1, 1))  # Pointer to the second sub-IFD\n",
    "    \n",
    "    # Step 3: Add remaining tags to extratags\n",
    "    for tag in tags.values():\n",
    "        if tag.code not in [257, 258, 259, 262, 270, 273, 277, 279, 305, 34665, 34853, 256]:  # Skip Exif and GPS IFDs\n",
    "            dtype = tag.dtype\n",
    "            value = tag.value\n",
    "    \n",
    "            if isinstance(value, str):\n",
    "                value = value.encode('utf-8')\n",
    "    \n",
    "            count = len(value) if isinstance(value, (bytes, bytearray)) else 1\n",
    "            extratags.append((tag.code, dtype, count, value))\n",
    "    \n",
    "    return image, (extratags,subifds,metadata_dict)\n",
    "    \n",
    "def process_xml_dict_3m(xml_string):\n",
    "    root = ET.fromstring(xml_string)\n",
    "    xmldict = XmlDictConfig(root)\n",
    "    return xmldict\n",
    "    \n",
    "def save_image(filename, image, metadata=None):\n",
    "    \"\"\"Save the image as a 4-channel TIFF using tifffile.\"\"\"\n",
    "    #tifffile.imwrite(filename, image, photometric='rgb',extratags=metadata[0],subifds = metadata[1])\n",
    "    if metadata is not None:\n",
    "        extratags = metadata[0]\n",
    "        subifds = metadata[1]\n",
    "    else:\n",
    "        extratags = None\n",
    "        subifds= None\n",
    "        \n",
    "    with tifffile.TiffWriter(filename) as tiff:\n",
    "        tiff.write(\n",
    "            image,\n",
    "            photometric='rgb',\n",
    "            extratags=extratags,\n",
    "            subifds=subifds\n",
    "        )\n",
    "\n",
    "# Create a directory to save homographies\n",
    "os.makedirs(\"homographies\", exist_ok=True)\n",
    "\n",
    "\n",
    "def align_images(image1, image2, band_name, green_image_path, set_title = \"set\"):\n",
    "    \"\"\"Align two images using ORB keypoints and cached affine transformation with quantization.\"\"\"\n",
    "    # Create a unique transformation filename\n",
    "    base_name = os.path.basename(green_image_path).replace(\"_G.TIF\", \"\")\n",
    "    affine_filename = f\"homographies/{band_name}_{set_title}_affine.npy\"\n",
    "\n",
    "    # Quantize images to uint8 if necessary\n",
    "    image1_8bit = quantize_to_uint8(image1)\n",
    "    image2_8bit = quantize_to_uint8(image2)\n",
    "\n",
    "    # Check if the affine transformation is already cached\n",
    "    if os.path.exists(affine_filename):\n",
    "        affine_matrix = np.load(affine_filename)\n",
    "    else:\n",
    "        # Convert images to grayscale if they are RGB\n",
    "        if len(image1_8bit.shape) == 3 and image1_8bit.shape[-1] == 3:\n",
    "            gray1 = cv2.cvtColor(image1_8bit, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray1 = image1_8bit\n",
    "\n",
    "        if len(image2_8bit.shape) == 3 and image2_8bit.shape[-1] == 3:\n",
    "            gray2 = cv2.cvtColor(image2_8bit, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray2 = image2_8bit\n",
    "\n",
    "        # Use ORB to find keypoints and descriptors\n",
    "        orb = cv2.ORB_create(5000)\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "        # Match descriptors using FLANN-based matcher\n",
    "        index_params = dict(algorithm=6, table_number=12, key_size=20, multi_probe_level=2)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "        # Filter matches using the ratio test\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.8 * n.distance]\n",
    "\n",
    "        if len(good_matches) < 3:\n",
    "            raise ValueError(\"Not enough good matches to compute affine transformation.\")\n",
    "\n",
    "        # Extract matched points\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Compute the affine transformation\n",
    "        affine_matrix, _ = cv2.estimateAffinePartial2D(dst_pts, src_pts, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "        # Save the affine transformation to disk\n",
    "        np.save(affine_filename, affine_matrix)\n",
    "\n",
    "    # Apply the affine transformation\n",
    "    sz = image1.shape\n",
    "    aligned_image = cv2.warpAffine(image2, affine_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return aligned_image\n",
    "\n",
    "def quantize_to_uint8(image):\n",
    "    \"\"\"Convert an image to uint8, scaling values if necessary.\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        if image.max() > 255:\n",
    "            image = (image / image.max()) * 255\n",
    "        image = image.astype(np.uint8)\n",
    "    return image\n",
    "def create_4_channel_image(green_image, red_image, rededge_image, nir_image):\n",
    "    \"\"\"Create a 4-channel image (G, R, RE, NIR).\"\"\"\n",
    "    return np.stack((green_image, red_image, rededge_image, nir_image), axis=-1)\n",
    "    \n",
    "def rescale_to_uint16(da):\n",
    "    da = np.where(np.isnan(da), 65535, da)\n",
    "    rescaled = (da * 65535).clip(0, 65535).astype(np.uint16)\n",
    "    \n",
    "    return rescaled\n",
    "    \n",
    "def process_multispec_set(green_image_path, output_directory):\n",
    "    \"\"\"Process one set of multispectral images and save as a 4-channel TIFF.\"\"\"\n",
    "    base_name = os.path.basename(green_image_path).replace(\"_G.TIF\", \"\")\n",
    "    # Load the green band image (reference image)\n",
    "    green_image, green_metadata = load_image(green_image_path)\n",
    "    \n",
    "    bands = {}\n",
    "    for band in [\"R\", \"RE\", \"NIR\"]:\n",
    "        band_image_path = green_image_path.replace(\"_G.TIF\", f\"_{band}.TIF\")\n",
    "        if os.path.exists(band_image_path):\n",
    "            bands[band], bands[band+\"_meta\"] = load_image(band_image_path)\n",
    "        else:\n",
    "            print(f\"Missing {band} band for {green_image_path}\")\n",
    "            return\n",
    "        # Construct the output filename MANUALLY CHANGE TO WHATEVER\n",
    "    sensor = \"3M\"\n",
    "    cal = \"SUNCAL\"\n",
    "    set_title = os.path.basename(os.path.normpath(output_directory))\n",
    "    output_filename = f\"{sensor}_{cal}_{set_title}_{base_name}.tif\"\n",
    "    output_path = os.path.join(output_directory, output_filename)\n",
    "    \n",
    "    # Align each band to the green image using cached homographies\n",
    "    aligned_red = align_images(green_image, bands[\"R\"], \"R\", green_image_path, set_title)\n",
    "    aligned_rededge = align_images(green_image, bands[\"RE\"], \"RE\", green_image_path, set_title)\n",
    "    aligned_nir = align_images(green_image, bands[\"NIR\"], \"NIR\", green_image_path, set_title)\n",
    "\n",
    "    r_green = calibrate_image(green_image, green_metadata[2]) \n",
    "\n",
    "    r_red = calibrate_image(aligned_red, bands[\"R_meta\"][2]) \n",
    "\n",
    "    r_rededge = calibrate_image(aligned_rededge, bands[\"RE_meta\"][2]) \n",
    "\n",
    "    r_nir = calibrate_image(aligned_nir, bands[\"NIR_meta\"][2]) \n",
    "\n",
    "    #rescale to 65535:\n",
    "    g  = rescale_to_uint16(r_green)\n",
    "    r = rescale_to_uint16(r_red)\n",
    "    re = rescale_to_uint16(r_rededge)\n",
    "    nir = rescale_to_uint16(r_nir)\n",
    "\n",
    "\n",
    "    # Create a 4-channel image\n",
    "    image_4ch = create_4_channel_image(g, r, re, nir)\n",
    "\n",
    "\n",
    "    # Save the 4-channel image\n",
    "    save_image(output_path, image_4ch,green_metadata)\n",
    "\n",
    "    rgb_image_path = green_image_path.replace(\"MS_G.TIF\", \"D.JPG\")\n",
    "    if os.path.exists(rgb_image_path):\n",
    "            \n",
    "        with Image.open(rgb_image_path) as img:\n",
    "            rgb = np.array(img)\n",
    "    else:\n",
    "        print(f\"Skipping due to missing jpg path: {rgb_image_path}\")\n",
    "        return\n",
    "        \n",
    "    #reszie to fit? (3m is at different res between G and RGB)\n",
    "    green_shape = green_image.shape\n",
    "    # Resize RGB to match green image dimensions\n",
    "    resized_rgb = cv2.resize(rgb, (green_shape[1], green_shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    aligned_rgb = align_images(green_image, resized_rgb, \"RGB\", base_name, set_title)\n",
    "    rgb_filename = f\"RGB_{set_title}_{base_name}.tif\"\n",
    "    rgb_path = os.path.join(output_directory, rgb_filename)\n",
    "    save_image(rgb_path, aligned_rgb,green_metadata)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_directory(input_dir, output_directory):\n",
    "    \"\"\"Process an entire directory with multiple sets of multispectral images.\"\"\"\n",
    "    input_dir = os.path.abspath(input_dir)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Find all green band images (reference images)\n",
    "    green_images = glob(os.path.join(input_dir, \"*_G.TIF\"))\n",
    "\n",
    "    # Process sets of 4 multispectral images in parallel with a progress bar\n",
    "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "        list(tqdm(executor.map(process_multispec_set, green_images, repeat(output_directory)), total=len(green_images)))\n",
    "\n",
    "    print(\"All images successfully processed.\")\n",
    "\n",
    "\n",
    "\n",
    "class XmlListConfig(list):\n",
    "    def __init__(self, aList):\n",
    "        for element in aList:\n",
    "            if element:\n",
    "                # treat like dict\n",
    "                if len(element) == 1 or element[0].tag != element[1].tag:\n",
    "                    self.append(XmlDictConfig(element))\n",
    "                # treat like list\n",
    "                elif element[0].tag == element[1].tag:\n",
    "                    self.append(XmlListConfig(element))\n",
    "            elif element.text:\n",
    "                text = element.text.strip()\n",
    "                if text:\n",
    "                    self.append(text)\n",
    "\n",
    "\n",
    "class XmlDictConfig(dict):\n",
    "    '''\n",
    "    Example usage:\n",
    "\n",
    "    >>> tree = ElementTree.parse('your_file.xml')\n",
    "    >>> root = tree.getroot()\n",
    "    >>> xmldict = XmlDictConfig(root)\n",
    "\n",
    "    Or, if you want to use an XML string:\n",
    "\n",
    "    >>> root = ElementTree.XML(xml_string)\n",
    "    >>> xmldict = XmlDictConfig(root)\n",
    "\n",
    "    And then use xmldict for what it is... a dict.\n",
    "    '''\n",
    "    def __init__(self, parent_element):\n",
    "        if parent_element.items():\n",
    "            self.update(dict(parent_element.items()))\n",
    "        for element in parent_element:\n",
    "            if element:\n",
    "                # treat like dict - we assume that if the first two tags\n",
    "                # in a series are different, then they are all different.\n",
    "                if len(element) == 1 or element[0].tag != element[1].tag:\n",
    "                    aDict = XmlDictConfig(element)\n",
    "                # treat like list - we assume that if the first two tags\n",
    "                # in a series are the same, then the rest are the same.\n",
    "                else:\n",
    "                    # here, we put the list in dictionary; the key is the\n",
    "                    # tag name the list elements all share in common, and\n",
    "                    # the value is the list itself \n",
    "                    aDict = {element[0].tag: XmlListConfig(element)}\n",
    "                # if the tag has attributes, add those to the dict\n",
    "                if element.items():\n",
    "                    aDict.update(dict(element.items()))\n",
    "                self.update({element.tag: aDict})\n",
    "            # this assumes that if you've got an attribute in a tag,\n",
    "            # you won't be having any text. This may or may not be a \n",
    "            # good idea -- time will tell. It works for the way we are\n",
    "            # currently doing XML configuration files...\n",
    "            elif element.items():\n",
    "                self.update({element.tag: dict(element.items())})\n",
    "            # finally, if there are no child tags and no attributes, extract\n",
    "            # the text\n",
    "            else:\n",
    "                self.update({element.tag: element.text})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1336a4-db73-44cb-84ad-1281abbe04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of threads for parallel processing\n",
    "n_threads = 1\n",
    "# Define termination criteria for the image registration algorithm; empirically determined:\n",
    "number_of_iterations = 100\n",
    "termination_eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c71e87e-3a0c-43ff-b192-5031df3274e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_24628\\123901474.py:343: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      "C:\\Users\\judoj\\AppData\\Local\\Temp\\ipykernel_24628\\123901474.py:311: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if element:\n",
      " 13%|██████████▋                                                                       | 11/84 [00:36<03:56,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to missing jpg path: C:\\Users\\judoj\\Documents\\programming\\msdata\\data\\RGBMS_pretraining\\3M_nitrogen\\DJI_20230814123356_0011_D.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▍                                                           | 23/84 [01:18<03:27,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to missing jpg path: C:\\Users\\judoj\\Documents\\programming\\msdata\\data\\RGBMS_pretraining\\3M_nitrogen\\DJI_20230828111824_0007_D.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▎                                                      | 28/84 [01:34<03:06,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to missing jpg path: C:\\Users\\judoj\\Documents\\programming\\msdata\\data\\RGBMS_pretraining\\3M_nitrogen\\DJI_20230828111842_0012_D.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 84/84 [05:20<00:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images successfully processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a processed folder if it doesn't exist\n",
    "processed_dir = \"../../data/msrgb_processed/3m_nitrogen/\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "input_folder = \"../../data/RGBMS_pretraining/3M_nitrogen\"\n",
    "process_directory(input_folder, processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de43fcaf-bdfe-450a-b13e-c02903b1d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image_bands(folder_path):\n",
    "    \"\"\"Load the first 4-channel TIFF image from the folder and display its bands.\"\"\"\n",
    "    # Find the first TIFF file in the folder\n",
    "    tiff_files = [f for f in os.listdir(folder_path) if f.endswith(\".tif\")]\n",
    "    if not tiff_files:\n",
    "        print(\"No TIFF files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    first_image_path = os.path.join(folder_path, tiff_files[0])\n",
    "    \n",
    "    # Load the image\n",
    "    image = tiff.imread(first_image_path)\n",
    "    \n",
    "    # Validate that it's a 4-channel image\n",
    "    if image.shape[-1] != 4:\n",
    "        print(\"The image does not have 4 channels.\")\n",
    "        return\n",
    "    \n",
    "    # Extract the bands\n",
    "    green_band = image[:, :, 0]\n",
    "    red_band = image[:, :, 1]\n",
    "    rededge_band = image[:, :, 2]\n",
    "    nir_band = image[:, :, 3]\n",
    "    \n",
    "    # Create a false-color image (NIR, Red, Green)\n",
    "    false_color_image = np.dstack((nir_band, red_band, green_band))\n",
    "    false_color_image = false_color_image / 65535\n",
    "\n",
    "    # Create a 10x zoom of the center crop\n",
    "    height, width, _ = false_color_image.shape\n",
    "    crop_size = (height // 20, width // 20)  # Crop size for a 10x zoom\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "\n",
    "    # Get the cropped region\n",
    "    cropped_image = false_color_image[\n",
    "        center_y - crop_size[0] // 2 : center_y + crop_size[0] // 2,\n",
    "        center_x - crop_size[1] // 2 : center_x + crop_size[1] // 2\n",
    "    ]\n",
    "\n",
    "    # Resize the cropped image to match the original dimensions\n",
    "    zoomed_image = cv2.resize(cropped_image, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # False color image\n",
    "    ax[0, 0].imshow(false_color_image)\n",
    "    ax[0, 0].set_title(\"False Color (NIR, Red, Green)\")\n",
    "    ax[0, 0].axis(\"off\")\n",
    "\n",
    "    # Individual bands\n",
    "    ax[0, 1].imshow(green_band, cmap=\"gray\")\n",
    "    ax[0, 1].set_title(\"Green Band\")\n",
    "    ax[0, 1].axis(\"off\")\n",
    "\n",
    "    ax[0, 2].imshow(red_band, cmap=\"gray\")\n",
    "    ax[0, 2].set_title(\"Red Band\")\n",
    "    ax[0, 2].axis(\"off\")\n",
    "\n",
    "    ax[1, 0].imshow(rededge_band, cmap=\"gray\")\n",
    "    ax[1, 0].set_title(\"RedEdge Band\")\n",
    "    ax[1, 0].axis(\"off\")\n",
    "\n",
    "    ax[1, 1].imshow(nir_band, cmap=\"gray\")\n",
    "    ax[1, 1].set_title(\"NIR Band\")\n",
    "    ax[1, 1].axis(\"off\")\n",
    "\n",
    "    # Zoomed-in section\n",
    "    ax[1, 2].imshow(zoomed_image)\n",
    "    ax[1, 2].set_title(\"10x Zoom (Center Crop)\")\n",
    "    ax[1, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6998e5e-0d2b-4897-bd5f-3167b917bf92",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../data/processed/3m_nitrogen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdisplay_image_bands\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/processed/3m_nitrogen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mdisplay_image_bands\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the first 4-channel TIFF image from the folder and display its bands.\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Find the first TIFF file in the folder\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m tiff_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tiff_files:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo TIFF files found in the folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../data/processed/3m_nitrogen'"
     ]
    }
   ],
   "source": [
    "\n",
    "display_image_bands(\"../data/processed/3m_nitrogen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff264-e0fc-40a8-b017-f7b89f9ccb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
